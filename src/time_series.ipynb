{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9ab658d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.graphics.tsaplots as sgt\n",
    "import statsmodels.tsa.stattools as sts\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "from scipy.stats.distributions import chi2\n",
    "sns.set()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bd394c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  2 of 2 completed\n"
     ]
    }
   ],
   "source": [
    "class DataCollection:\n",
    "    \"\"\"\n",
    "    get_data : Param:   companies: Companies shortname splitted with space.\n",
    "                        start_date: Start date for the stock data.\n",
    "                        end_date:  Close date for the stock data.\n",
    "               Returns: df: Cleaned Dataframe consisting of Close prices of the provided companies.   \n",
    "    \n",
    "    preprocess_data : Param: df: Dataframe\n",
    "                    Returns: df: Dataframe with no missing values. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "      \n",
    "        \n",
    "    def get_data(self, companies, start_date, end_date):\n",
    "        \"\"\"\n",
    "        1. Scraping stock data from yahoo finance library\n",
    "        2. Removing all other columns and keeping only Closing price.\n",
    "        \"\"\"\n",
    "        df = pd.DataFrame()\n",
    "        try:\n",
    "            raw_data = yf.download(tickers=companies, start=start_date, end=end_date, \n",
    "                                        interval=\"1d\", group_by = 'ticker', auto_adjust=True, threads=True)\n",
    "            for company in companies.split():\n",
    "                df[company+\"_close\"] = raw_data[company.upper()][\"Close\"]\n",
    "            return self.preprocess_data(df)\n",
    "        except Exception as exp:\n",
    "            raise Exception\n",
    "    \n",
    "    def preprocess_data(self, df):\n",
    "        \"\"\"\n",
    "        1. Removing dates from non-business days (Saturday and Sunday).\n",
    "        2. Replacing missing values by front filling method.\n",
    "        \"\"\"\n",
    "        df = df.asfreq('b')\n",
    "        df = df.fillna(method=\"ffill\")\n",
    "        return df\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    df = DataCollection().get_data(companies=\"msft aapl\", start_date=\"2015-01-01\", end_date=\"2021-01-01\")\n",
    "    size = int(len(df)*0.8)\n",
    "    df_train, df_test = df.iloc[:size], df.iloc[size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e0ed5c38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class EDA:\n",
    "    def __init__(self, df_train):\n",
    "        self.df_train = df_train\n",
    "    \n",
    "    \n",
    "    def white_noise_check(self):\n",
    "        \"\"\"\n",
    "        Check for mean is 0, std is constant and no autocorelation.\n",
    "        These plot might not be good visualization approach of autocorelation. \n",
    "        We can later use ACF or PACF to check for autocorelation parameter of white noises.\n",
    "        \"\"\"\n",
    "        for df in self.df_train.columns:\n",
    "            self.df_train[df+\"_white_noise\"] = np.random.normal(loc=self.df_train[df].mean(), scale=self.df_train[df].std(), \n",
    "                                                 size=len(df_train))\n",
    "            df_train[df+\"_white_noise\"].plot(figsize=(15,5))\n",
    "            plt.title(df+\"_white_noise\", size=20)\n",
    "            plt.show()\n",
    "            df_train[df].plot(figsize=(15,5))\n",
    "            plt.show()\n",
    "    \n",
    "    \n",
    "    def stationarity_check(self):\n",
    "        \"\"\"\n",
    "        1. Stationarity test by David Dickey and Wanye Fuller known as agumented fuller\n",
    "        2. Check for mean and  std is constant and there is no seasonility.\n",
    "        \"\"\"\n",
    "        for df in self.df_train.columns:\n",
    "            ad_fuller = sts.adfuller(self.df_train[df])\n",
    "            print(\"test_statistics for {}: {}\".format(df,ad_fuller[0]))\n",
    "            print(\"pvalue for {}: {}\".format(df, ad_fuller[1]))\n",
    "       \n",
    "    \n",
    "    def seasonality_check(self):\n",
    "        \"\"\"\n",
    "        1. Additive Navie Decompostion for checking seasonality\n",
    "        \"\"\"\n",
    "        for df in self.df_train.columns:\n",
    "            additive_decomposition = seasonal_decompose(self.df_train[df], model=\"additive\")\n",
    "            additive_decomposition.plot()\n",
    "            plt.show()\n",
    "\n",
    "            \n",
    "    def autocorelation_factor_check(self, lags):\n",
    "        \"\"\"\n",
    "        1. ACF between different lags we are interested in\n",
    "        lags=40: The last 40 period before the current one.\n",
    "        zero=False: Ignores the current period value\n",
    "        \"\"\"\n",
    "        for df in self.df_train.columns:\n",
    "            sgt.plot_acf(self.df_train[df], lags=lags, zero=False)\n",
    "            plt.title(\"ACF {}\".format(df))\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "    def partial_autocorelation_factor_check(self, lags):\n",
    "        \"\"\"\n",
    "        1. PACF between different lags we are interested in.\n",
    "        lags=40: The last 40 period before the current one.\n",
    "        zero=False: Ignores the current period value\n",
    "        method: Various methods are available.OLS is one of those i.e. Order of Least Squares\n",
    "        \"\"\"\n",
    "        for df in self.df_train.columns:\n",
    "            sgt.plot_pacf(self.df_train[df], lags=lags, zero=False, method=('ols'))\n",
    "            plt.title(\"PACF {}\".format(df))\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    eda = EDA(df_train)\n",
    "    \"\"\"\n",
    "    Use these to check and understand the data more:\n",
    "    1. eda.white_noise_check()\n",
    "    2. eda.stationarity_check()\n",
    "    3. eda.seasonality_check()\n",
    "    4. eda.autocorelation_factor_check(lags=40)\n",
    "    5. eda.partial_autocorelation_factor_check(lags=40)\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a87bc577",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def log_likelihood_test(self, model_list_1, model_list_2,index_of_model_list, DF):\n",
    "        l1 = model_list_1[index_of_model_list].llf\n",
    "        l2 = model_list_2[index_of_model_list].llf\n",
    "        test_statistic = (2*(l2-l1))\n",
    "        pvalue = chi2.sf(test_statistic, DF).round(3)\n",
    "        return pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e9f23514",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.176\n"
     ]
    }
   ],
   "source": [
    "class Model:\n",
    "    def __init__(self, df_train):\n",
    "        self.df_train = df_train\n",
    "        \n",
    "        \n",
    "    def  auto_regression_model(self, order, display_summary):\n",
    "        \"\"\"\n",
    "        order=(x,y): x= No. of past values(lags) we want to incorporate into the model\n",
    "                     y= 0 if not taking any residuals into consideration, 1 if taking them into considerations\n",
    "        \"\"\"\n",
    "        model_list = []\n",
    "        for df in self.df_train.columns:\n",
    "            ar_model = ARMA(self.df_train[df], order=order)\n",
    "            result_of_ar_model = ar_model.fit()\n",
    "            if display_summary:\n",
    "                print(\"\\n\\n\\n\\n\"+df)\n",
    "                print(result_of_ar_model.summary())\n",
    "            model_list.append(result_of_ar_model)\n",
    "        return model_list\n",
    "            \n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    model = Model(df_train)\n",
    "    test = Test()\n",
    "    \"\"\"\n",
    "    we can try out different orders. (1, 0), (2, 0), (3, 0), (4, 0) for all the given columns.\n",
    "    Our goal here is to have a higher log likelihood ratio. And if we see the highest LLR value, take the lag before that. It will prevent overfitting.\n",
    "    By observation, Seems like for column msft_close, we can consider lag of 4.\n",
    "    While for column aapl_close,  we can consider lag of 3.\n",
    "    \"\"\" \n",
    "    model_list_1 = model.auto_regression_model(order=(1, 0), display_summary=False)\n",
    "    model_list_2 = model.auto_regression_model(order=(1, 0), display_summary=False)\n",
    "    result = test.log_likelihood_test(model_list_1, model_list_2, index_of_model_list=1, DF=1)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739e69b2",
   "metadata": {},
   "source": [
    "But as in as we should not rely on AR model because we have a non stationary data.\n",
    "Our best bet is transforming the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e2681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cc9664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addf8f90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ed1a00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
